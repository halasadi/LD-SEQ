---
title: "Reading meta data from Mattheston et al 2015"
author: "Hussein Al-Asadi"
date: 2015-12-14
---

**Last updated:** `r Sys.Date()`

**Code version:** `r system("git log -1 --format='%H'", intern = TRUE)`

```{r chunk-options, include=FALSE}
source("chunk-options.R")
```

```{r}
metadata <- read.csv("../data/nature16152-s2.csv", stringsAsFactors=FALSE, header=TRUE)
# hard cut off of 2.5X. Read somewhere online that you need at least 50 samples for imputation. Why not?
candidates <- metadata$Coverage > 2.5 & as.numeric(metadata$SNPs) > 650000 
#candidates <- as.numeric(metadata$SNPs[candidates]) > 700000 
print("Number of SNPs for each candidate: ")
print(metadata$SNPs[candidates])
hist(metadata$Coverage[candidates], 20, xlim = c(0, 30), xlab = "coverage of candidates", main = "")
print(metadata$Country[candidates])
print(metadata$Archaeological.culture[candidates])
hist(as.numeric(metadata$Min.Date[candidates]))
```

## Session information

```{r info}
sessionInfo()
```
