\documentclass[10pt,a4paper,draft]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\title{LDSP- Linear Detection of Selection in Pooled sequence data}
\date{}
\setlength\parindent{0pt}
\author{Matthew Stephens \& Hussein Al-Asadi}
\begin{document}
\maketitle
\section{Introduction}
We break up the process into two phases.

\textbf{Phase I - better estimate frequency using haplotypic information}:
The Intuition is that data at each SNP are binomial counts, which help estimate the frequency of a SNP in a pool, but they don't
tell you the frequency exactly, they are noisy. But by combining information across multiple corrected SNPs, you can improve the estimated frequency of the test SNP

\textbf{Phase II - detect selection using improved frequency estimate}:
To detect selection, we find sites that have had significant changes in their frequency compared to the founding population. We can do this by using a linear model which also allows us to model genetic drift with a normal error term.

\section{Phase I}
\subsection{Prior from Li \& Stephens}
Consider one lineage for now.

Let  $y = (y_1, y_2, ..., y_p)'$ denote the vector of allele frequencies in the study sample.
Let $E[y_{i}] = \mu_{i}$ and the frequency of the test SNP be $y_{t}$  and $M$ denote the $2m$x$p$ panel (i.e. $2m$ haplotypes and $p$ SNPs). As in (Wen \& Stephens, 2010), we assume 
\begin{equation}
\vec{y} |M \sim N_p(\mu, \Sigma) \label{eq:prior}
\end{equation}
(Wen \& Stephens, 2010) derived the estimates for $\mu$ and $\Sigma$ from the haplotype copying model presented in (Li \& Stephens, 2003).
\begin{equation}
\hat{\mu} = (1-\theta)f^{panel} + \frac{\theta}{2}1 
\end{equation}
\begin{equation}
\hat{\Sigma} = (1-\theta)^2S + \frac{\theta}{2}(1-\frac{\theta}{2})I
\end{equation}
and $S$ is obtained from $\Sigma^{panel}$, specifically,
 \begin{equation}
   S_{i,j} = \left\{
     \begin{array}{lr}
       \Sigma_{i,j}^{panel} &  i =j\\
       e^{-\frac{-\rho_{i,j}}{2m}} \Sigma_{i,j}^{panel} &  i \neq j
     \end{array}
   \right.
\end{equation} 
and,
\begin{equation}
\theta = \frac{(\sum_{i=1}^{2m-1} \frac{1}{i})^{-1}}{2m + (\sum_{i=1}^{2m-1} \frac{1}{i})^{-1}}
\end{equation}

\iffalse
The distribution of $\{y_j: j \neq t\}$ given the test SNP,
\begin{equation}
\{y_i: i \neq t\} | y_t \sim N_{p-1}(\bar{\mu}, \bar{\Sigma}) \label{cond}
\end{equation}
where
\begin{align*}
\bar{\mu} = \vec{\mu_{i \neq t}} + \Sigma_{i \neq t, t}\frac{1}{\sigma_t^2}(y_t-\mu_{t}) 
\end{align*}
and
\begin{align*}
\hat{\Sigma} = \Sigma_{i \neq t, i \neq t} - \Sigma_{i \neq t, t}\frac{1}{\sigma_t^2}\Sigma_{t, i \neq t}
\end{align*}
\fi

\subsection{Data at SNP $i$}
Let $(n_i^0, n_i^1)$ denote the counts of "0" and "1" alleles at SNP $i$ and $n_i = n_i^0 + n_i^1$. Then 
\begin{align*}
n_i^1 \sim Bin(n_i, y_i) \ \dot{\sim}  \ N(n_iy_i, n_iy_i(1-y_i)) \label{eq:napprox}
\end{align*}
where $y_i$ is the true population frequency of the SNP $i$ "1" allele. 


\begin{equation}
\implies  \hat{y_i} | y_i \ \sim \ N(y_i, \frac{y_i(1-y_i)}{n_i})
\end{equation}
where $\hat{y_i} = \frac{n_i^1}{n_i}$ \\
\\
Next we replace $y_i$ by $\hat{y_i}$ in the variance for tractibility issues. Therefore,

\begin{equation}
\hat{y_i} | y_i \ \dot{\sim} \ N(y_i, \frac{\hat{y_i}(1-\hat{y_i})}{n_i}) \label{bin}
\end{equation}

Letting $y^{true}_i = y_i$ and $y^{obs}_i = \hat{y_i}$,  we see that (don't we assume independence here?)
\begin{equation}
\vec{y^{obs}} | \vec{y^{true}} \sim N_p(\vec{y^{true}}, \ diag(\epsilon_1,...,\epsilon_p))
\end{equation}
where $\epsilon_i = \frac{y^{obs}_i (1-y^{obs}_i)}{n_i}$ 

\subsection{Incorporating Dispersion}
In the distribution of $\vec{y}$, we assumed that the panel and study individuals are from the sample population, and the parameters $\theta$ and $\rho$ are estimated without error. Deviations from these assumptions will cause over-dispersion: the true allele frequencies will lie further from their expected values than the model predicts. To allow this, we modify equation \ref{eq:prior} by introducing an over-dispersion parameter $\sigma^2$.
\begin{equation}
\vec{y^{true}}|M \sim N_p(\hat{\mu}, \sigma^2\hat{\Sigma})
\end{equation}

We estimate $\sigma^2$ by maximizing the multivariate normal likelihood:
\begin{equation}
 \vec{y^{obs}}|M \sim N_p(\hat{\mu}, \sigma^2\hat{\Sigma} + diag(\epsilon_1,...,\epsilon_p))
\end{equation}

We use Bayes theorem to obtain the distribution for the true frequencies conditional on the observed data.
\begin{align*}
P(\vec{y^{true}} | \vec{y^{obs}}, M) \propto P(\vec{y^{obs}} | \vec{y^{true}}) P(\vec{y^{true}}|M)
\end{align*}

Let
\begin{equation}
\bar{\Sigma} = \big(\frac{\hat{\Sigma}^{-1}}{\sigma^2} + diag(\frac{1}{\epsilon_1},..., \frac{1}{\epsilon_p})\big)^{-1}
\end{equation}
and,
\begin{equation}
\bar{\theta} = (\frac{\hat{\Sigma}^{-1}}{\sigma^2}\hat{\mu} + diag(\frac{1}{\epsilon_1},..., \frac{1}{\epsilon_p}) \ \vec{y^{obs}}) \ \bar{\Sigma}
\end{equation}
Then,

\begin{equation}
\vec{y^{true}} | \vec{y^{obs}}, M \sim N_p(\bar{\theta}, \bar{\Sigma})
\end{equation}
Therefore a natural point estimate for $\vec{y^{true}}$ is $\bar{\theta}$.


\iffalse
\begin{equation}
\sim N_p\Big((\frac{\hat{\Sigma}^{-1}}{\sigma^2} + \frac{I}{\epsilon^2})^{-1}(\frac{\hat{\Sigma}^{-1}\hat{\mu}}{\sigma^2} + \frac{\vec{y^{obs}}}{\epsilon^2}), (\frac{\hat{\Sigma}^{-1}}{\sigma^2} + \frac{I}{\epsilon^2})^{-1}\Big)\label{likl}
\end{equation}
\fi

\section{Phase II - estimating $\beta$}
Let $f_{i,k,j}$ denote the frequency of the $j$th SNP in population $i$ and replicate $k$. Then,

\begin{equation}
log(\frac{1-f_{i,k,j}}{f_{i,k,j}}) = \mu_j + \beta_{j} g_i + \epsilon
\end{equation}

where $\epsilon \sim N_(0, \sigma_d^2)$, $\sigma_d^2$ is the variance due to drift, $\mu_j$ is the frequency of the $j$the SNP in the founding population and 
\[
   g_{i} = \left\{
     \begin{array}{lr}
       -1 &  i =0\\
        0 &  i =1 \\
        1 &  i =2
     \end{array}
   \right.
\]

The intuition here is that sites with large $\beta$ coefficients are under selection.
\end{document}