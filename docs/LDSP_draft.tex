\documentclass[10pt,a4paper,draft]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\title{LDSP- Linear Detection of Selection in Pooled sequence data}
\date{}
\author{Matthew Stephens \& Hussein Al-Asadi}
\begin{document}
\maketitle
\section{Introduction}
We break up the process into two phases.

\textbf{Phase I}:
The Intuition is that data at each SNP are binomial counts, which help estimate the frequency of a SNP in a pool, but they don't
tell you the frequency exactly, they are noisy. But by combining information across multiple corrected SNPs, you can improve the estimated frequency of the test SNP

\textbf{Phase II}:
After we estimate the frequency of the putatively selected SNP in each replicate population, we estimate the group effect using a linear model which also allows us to model genetic drift with a normal error term.. The idea is that in the positively selected population, the group effect will be positive while negative in the negatively selected population, and 0 in the neutrally evolving population.

\section{Phase I}
Consider one lineage for now.

Let  $y = (y_1, y_2, ..., y_p)'$ denote the vector of allele frequencies in the study sample.
Let $E[y_{i}] = \mu_{i}$ and the frequency of the test SNP be $y_{t}$ . As in (Wen \& Stephens, 2010), we assume 
\begin{equation}
\vec{y} \sim N_p(\mu, \Sigma) \label{eq:prior}
\end{equation}
where $\mu$ and $\Sigma$ is calculated from a reference panel consisting of $2m$ haplotypes and $p$ SNPs. (Wen \& Stephens, 2010) derived the estimates for $\mu$ and $\Sigma$ from the haplotype copying model presented in (Li \& Stephens, 2003).
\begin{equation}
\hat{\mu} = (1-\theta)f^{panel} + \frac{\theta}{2}1 
\end{equation}
\begin{equation}
\hat{\Sigma} = (1-\theta)^2S + \frac{\theta}{2}(1-\frac{\theta}{2})I
\end{equation}
and $S$ is obtained from $\Sigma^{panel}$, specifically,
 \begin{equation}
   S_{i,j} = \left\{
     \begin{array}{lr}
       \Sigma_{i,j}^{panel} &  i =j\\
       e^{-\frac{-\rho_{i,j}}{2m}} \Sigma_{i,j}^{panel} &  i \neq j
     \end{array}
   \right.
\end{equation} 
and,
\begin{equation}
\theta = \frac{(\sum_{i=1}^{2m-1} \frac{1}{i})^{-1}}{2m + (\sum_{i=1}^{2m-1} \frac{1}{i})^{-1}}
\end{equation}

\iffalse
The distribution of $\{y_j: j \neq t\}$ given the test SNP,
\begin{equation}
\{y_i: i \neq t\} | y_t \sim N_{p-1}(\bar{\mu}, \bar{\Sigma}) \label{cond}
\end{equation}
where
\begin{align*}
\bar{\mu} = \vec{\mu_{i \neq t}} + \Sigma_{i \neq t, t}\frac{1}{\sigma_t^2}(y_t-\mu_{t}) 
\end{align*}
and
\begin{align*}
\hat{\Sigma} = \Sigma_{i \neq t, i \neq t} - \Sigma_{i \neq t, t}\frac{1}{\sigma_t^2}\Sigma_{t, i \neq t}
\end{align*}
\fi

\subsection{Data at SNP $i$}
Let $(n_i^0, n_i^1)$ denote the counts of "0" and "1" alleles at SNP $i$ and $n_i = n_i^0 + n_i^1$. Then 
\begin{align*}
n_i^1 \sim Bin(n_i, X_i) \ \dot{\sim}  \ N(n_iX_i, n_iX_i(1-X_i)) \label{eq:napprox}
\end{align*}
where $X_i$ is the true population frequency of the SNP $i$ "1" allele. 


\begin{equation}
\implies  \hat{X_i} | X_ti \ \sim \ N(X_i, \frac{X_i(1-X_i)}{n_i})
\end{equation}
where $\hat{X_i} = \frac{n_i^1}{n_i}$ \\
\\
Next we replace $X_i$ by $\hat{X_i}$ in the variance for tractibility issues. Therefore,

\begin{equation}
\hat{X_i} | X_i \ \dot{\sim} \ N(X_i, \frac{\hat{X_i}(1-\hat{X_i})}{n_i}) \label{bin}
\end{equation}


\subsection{Incorporating Dispersion}

Letting $y^{obs}_i = \hat{X_i}$ from equation \ref{bin}, we see that
\begin{equation}
\vec{y^{obs}} | \vec{y^{true}} \sim N_p(\vec{y^{true}}, \ diag(\epsilon_1,...,\epsilon_p))
\end{equation}
where $\epsilon_i = \frac{y^{obs}_i (1-y^{obs}_i)}{n}$ and $n$ is the total coverage for SNP $i$ \\
\\
In the distribution of $\vec{y}$, we assumed that the panel and study individuals are from the sample population, and the parameters $\theta$ and $\rho$ are estimated without error. Deviations from these assumptions will cause over-dispersion: the true allele frequencies will lie further from their expected values than the model predicts. To allow this, we modify equation \ref{eq:prior} by introducing an over-dispersion parameter $\sigma^2$.
\begin{equation}
\vec{y^{true}} \sim N_p(\hat{\mu}, \sigma^2\hat{\Sigma})
\end{equation}

Combining both equations, we obtain,
\begin{equation}
 \vec{y^{obs}} \sim N_p(\hat{\mu}, \sigma^2\hat{\Sigma} + diag(\epsilon_1,...,\epsilon_p))
\end{equation}
where we can estimate $\sigma^2$ by maximum likelihood.

We use Bayes theorem to obtain the distribution for the true frequencies conditional on the observed data (as derived in Wen \& Stephens).
\begin{align*}
P(\vec{y^{true}} | \vec{y^{obs}}) = \frac{P(\vec{y^{obs}} | \vec{y^{true}}) P(\vec{y^{true}})}{P(\vec{y^{obs}})} 
\end{align*}

\iffalse
\begin{equation}
\sim N_p\Big((\frac{\hat{\Sigma}^{-1}}{\sigma^2} + \frac{I}{\epsilon^2})^{-1}(\frac{\hat{\Sigma}^{-1}\hat{\mu}}{\sigma^2} + \frac{\vec{y^{obs}}}{\epsilon^2}), (\frac{\hat{\Sigma}^{-1}}{\sigma^2} + \frac{I}{\epsilon^2})^{-1}\Big)\label{likl}
\end{equation}
\fi
\subsection{Estimating the true frequency at SNP t}
....
%We can calculate the likelihood for the frequency at SNP $j$ using Bayes theorem
%\begin{equation}
%L(f_{i,k,j}^{true} | \vec{f_{i,k}^{obs}}) = P(\vec{f_{i,k}^{obs}} | f_{i,k,j}^{true}) = %\frac{P(f_{i,k,j}^{true}|\vec{f_{i,k}^{obs}}) P(\vec{f_{i,k}^{obs}})} {P(f_{i,k,j}^{true})} 
%\end{equation}
%Why do we maximize the likelihood, don't we already have the best case (i.e. eqn \ref{likl})?

\section{Phase II - estimating $\beta$}
Let $f_{i,k,j}$ denote the frequency of the $j$th SNP in population $i$ and replicate $k$. Then,

\begin{equation}
log(\frac{1-f_{i,k,j}}{f_{i,k,j}}) = \mu_j + \beta_j g_i + \epsilon
\end{equation}

where $\epsilon \sim N_(0, \sigma_d^2)$, $\sigma_d^2$ is the variance due to drift, $\mu_j$ is the frequency of the $j$the SNP in the founding population and 
\[
   g_{i} = \left\{
     \begin{array}{lr}
       -1 &  i =0\\
        0 &  i =1 \\
        1 &  i =2
     \end{array}
   \right.
\]

The intuition here is that sites with large $\beta$ coefficients are under selection.
\end{document}